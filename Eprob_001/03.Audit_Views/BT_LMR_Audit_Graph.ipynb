{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fae85bb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"g = audit_graph(fname = 'Test',\\n                query = sql_t,\\n                attrs = ['var2'],\\n                exclude_nodes = [],) # 'N0.0.4.5'\\n\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Audit Graph\n",
    "\n",
    "#------------\n",
    "# Imports and Classes\n",
    "#------------\n",
    "import graphviz\n",
    "import sqlparse\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "\n",
    "class MyStmts:\n",
    "    def __init__(self):\n",
    "        self.tokens = []\n",
    "        self.ttype = None\n",
    "        self.value = ''\n",
    "\n",
    "#------------\n",
    "# Helper 01 (used in Main 01)\n",
    "#------------\n",
    "def gen_pl(query):\n",
    "    '''\n",
    "    pl: parsed list\n",
    "    '''\n",
    "\n",
    "    # initialize df_q\n",
    "    df_q = pd.DataFrame()\n",
    "    df_q.at[0, 'QUERY_TEXT'] = query # assign sql text to df cell\n",
    "    \n",
    "    # initialize pl, to handle multiple statements\n",
    "    pl = MyStmts()\n",
    "\n",
    "    # process pl\n",
    "    for index, row in df_q.iterrows(): #multiple queries in SF\n",
    "        sql = row['QUERY_TEXT']\n",
    "        sql = re.sub(r'--.*', '', sql) # remove comment\n",
    "        sql = sql.replace(\",\", \",\\n\") # break commas\n",
    "        parsed = sqlparse.parse(sql) \n",
    "        root = parsed[0]\n",
    "        pl.tokens.append(root)\n",
    "        pl.value += row['QUERY_TEXT'] + \"\\n\"\n",
    "    \n",
    "    return pl\n",
    "\n",
    "#------------\n",
    "# Helper 02 (used in Main 01)\n",
    "#------------\n",
    "def sql2tree(node, pnode_id='', local_node_id = 0, df = pd.DataFrame()):\n",
    "    '''\n",
    "    node is pl (parsed list of sqlparse objects)\n",
    "    '''\n",
    "    if node is None:\n",
    "        return\n",
    "    \n",
    "    node_id = 'N0' if pnode_id=='' else f'{pnode_id}.{local_node_id}'\n",
    "    ntype = str(node.ttype)\n",
    "    Lines = len(str(node).splitlines())\n",
    "    value = '  ' * node_id.count('.') + str(node.value) # add indentation\n",
    "    \n",
    "    new_row = pd.Series({'Node_ID': node_id, 'Type': ntype, 'Lines': Lines, 'Value': value,})\n",
    "\n",
    "    df = df.append(new_row, ignore_index=True)\n",
    "    \n",
    "    if node.ttype is None :\n",
    "        for i, child in enumerate(node.tokens):\n",
    "            df = sql2tree(child, node_id, i, df) # index start from 0\n",
    "            \n",
    "    return df\n",
    "\n",
    "#------------\n",
    "# Helper 03A (used by Main 01)\n",
    "#------------\n",
    "\n",
    "def get_from_nodes(node, pnode_id='', local_node_id=0, from_nodes=[], parent_has_from=True):\n",
    "    '''\n",
    "    node is pl (parsed list of sqlparse objects)\n",
    "    '''\n",
    "    if node is None:\n",
    "        return from_nodes\n",
    "\n",
    "    node_id = 'N0' if pnode_id == '' else f'{pnode_id}.{local_node_id}'\n",
    "    \n",
    "    from_index = None\n",
    "    has_from = False  # Initialize has_from as False\n",
    "            \n",
    "    if node.ttype is None:\n",
    "        # add this node\n",
    "        if node_id != 'N0': # N0 has special problem, exclude from list\n",
    "\n",
    "            from_nodes.append(node_id)\n",
    "        \n",
    "        # get into a subset of children nodes \n",
    "        for f, cnode in enumerate(node.tokens):\n",
    "            if cnode.value.lower() == 'from':  # Compare case-insensitive\n",
    "                from_index = f\n",
    "                has_from = True\n",
    "        \n",
    "        for i, cnode in enumerate(node.tokens):\n",
    "            if ((from_index is not None and i > from_index) or (from_index is None and parent_has_from)) and len(cnode.value)>250:\n",
    "                from_nodes = get_from_nodes(cnode, node_id, i, from_nodes, has_from)           \n",
    "\n",
    "    return from_nodes\n",
    "        \n",
    "#------------\n",
    "# Helper 03B (used by Main 01)\n",
    "#------------\n",
    "def get_nodes_with_text(df, include_list):\n",
    "    \n",
    "    cond1 = df['Node_ID'] != 'N0' # remove top level, which is a extra level to handle multiple statements\n",
    "    cond2 = df['Value'].str.contains('|'.join(include_list)) # contains keywords\n",
    "    cond3 = df['Type']=='None' # only plot nodes with children\n",
    "    cond4 = df['Value'].str.len()>0 # 200\n",
    "\n",
    "    result = df[cond1 & cond2 & cond3 & cond4]['Node_ID'].to_list()\n",
    "    return result\n",
    "    \n",
    "\n",
    "#------------\n",
    "# Helper 04 (used in 06 gen_nodes)\n",
    "#------------\n",
    "def getNodebyID(s, node_id):\n",
    "        \n",
    "    ids = node_id.split('.')\n",
    "    s = s.tokens # handle first 0\n",
    "    ids = ids[1:]\n",
    "    for i in ids:\n",
    "        s = s[int(i)]\n",
    "            \n",
    "    return s\n",
    "    \n",
    "#------------\n",
    "# Helper 05 (used in 06 gen_nodes)\n",
    "#------------\n",
    "def comb_item(my_list, word):\n",
    "    '''\n",
    "    example: combine two nodes 'and ', 'var' into one node 'and var'\n",
    "    '''\n",
    "    new_list = []\n",
    "\n",
    "    i = 0\n",
    "    while i < len(my_list):\n",
    "        if my_list[i] == word and i < len(my_list) - 1:\n",
    "            new_string = f'{my_list[i]} {my_list[i + 1]}'\n",
    "            new_list.append(new_string)\n",
    "            i += 2\n",
    "        else:\n",
    "            new_list.append(my_list[i])\n",
    "            i += 1\n",
    "    return new_list\n",
    "\n",
    "#------------\n",
    "# Helper 06 (to provide cnodes list to Helper 07 find_nodes_between, called in 98 gen_nodes_list)\n",
    "#------------\n",
    "def get_cnodes_list(pl,node_id):\n",
    "    '''\n",
    "    pl: parsed list of sql statements\n",
    "    '''\n",
    "\n",
    "    pnode = getNodebyID(pl,node_id)\n",
    "    \n",
    "    cnodes = []\n",
    "\n",
    "    for i, n in enumerate(pnode.tokens):\n",
    "        cnode = {}\n",
    "        cnode['index'] = str(i)\n",
    "        cnode['text'] = str(n.value)\n",
    "        cnodes.append(cnode)\n",
    "    \n",
    "    return cnodes\n",
    "\n",
    "#------------\n",
    "# Helper 07 (generate ignore in Helper 97 gen_nodes, called in 98 gen_nodes_list)\n",
    "#------------\n",
    "def find_nodes_between(pnode_id, nodes, start_text, end_text):\n",
    "    '''\n",
    "    get ['3','4'] etc. list of nodes to ignore in gen_nodes\n",
    "    nodes: xx\n",
    "    '''\n",
    "    start_index = None\n",
    "    end_index = None\n",
    "\n",
    "    for i, node in enumerate(nodes):\n",
    "        node['node_id'] = f'{pnode_id}.{node[\"index\"]}'\n",
    "        if node[\"text\"] == start_text:\n",
    "            start_index = i\n",
    "        elif node[\"text\"] == end_text:\n",
    "            end_index = i\n",
    "            break  # Stop searching once end_text is found\n",
    "\n",
    "    if start_index is not None and end_index is not None and start_index < end_index:\n",
    "        return [node['node_id'] for node in nodes[start_index + 1:end_index]]\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "#------------\n",
    "# Helper 08 (called in Helper 98 gen_nodes_list)\n",
    "#------------\n",
    "def excl_nodes(source_nodes, exclude_list):\n",
    "    \n",
    "    def str_contains_substrs(input_string, substring_list):\n",
    "        for substring in substring_list:\n",
    "            if substring in input_string:\n",
    "                return True\n",
    "        return False\n",
    "    \n",
    "    return [node for node in source_nodes if not str_contains_substrs(node['text'], exclude_list)]\n",
    "\n",
    "#------------\n",
    "# Helper 09 (generate replace in Helper 97 gen_nodes, called in 98 gen_nodes_list)\n",
    "#------------\n",
    "def find_nodes_replace(pnode_id, cnodes, replace_nodes):\n",
    "    replace_list = []\n",
    "    \n",
    "    for cnode in cnodes:\n",
    "        if f\"{pnode_id}.{cnode['index']}\" in replace_nodes:\n",
    "            replace_list.append(cnode['index'])\n",
    "    \n",
    "    return replace_list\n",
    "\n",
    "\n",
    "#------------\n",
    "# Helper 10 (called in Main 01)\n",
    "#------------\n",
    "def excl_steps(input_nodes, exclude_nodes):\n",
    "    '''\n",
    "    If any input node_id contains a string in the exclude_nodes list, then exclude it.\n",
    "    '''\n",
    "    remaining_nodes = []\n",
    "    for node_id in input_nodes:\n",
    "        exclude = False\n",
    "        for enode_id in exclude_nodes:\n",
    "            if enode_id in node_id:\n",
    "                exclude = True\n",
    "                break\n",
    "        if not exclude:\n",
    "            remaining_nodes.append(node_id)\n",
    "    return remaining_nodes\n",
    "\n",
    "#------------\n",
    "# Helper 97 (used in 98 gen_nodes_list)\n",
    "#------------\n",
    "def gen_nodes(pl, node_id, replace=[], ignore=[], comb_word='', colors=[]):\n",
    "    '''\n",
    "    pl: root statment\n",
    "    node_id: N0.1.1 etc.\n",
    "    replace: ['1','2'] etc. list of child ids to ignore, replace node text with 'N0.1.1' etc.\n",
    "    ignore: ['1','2'] etc. list of child ids to ignore, replace with '...'\n",
    "    comb_word: e.g. combine two nodes: \"and \", \"a>b\", into one node \"and a>b\"\n",
    "    colors: ['white','red'] etc.\n",
    "    '''\n",
    "\n",
    "    # pnode label\n",
    "    pnode_ = f'{node_id}'\n",
    "    \n",
    "    # cnodes labels\n",
    "    pnode = getNodebyID(pl,node_id) \n",
    "\n",
    "    cnodes_ = []\n",
    "    colors_ = []\n",
    "    \n",
    "    last_i = 0\n",
    "    \n",
    "    for i, n in enumerate(pnode.tokens):\n",
    "        \n",
    "        if str(n.ttype) not in [\n",
    "            'Token.Text.Whitespace.Newline',\n",
    "            'Token.Punctuation',\n",
    "            'Token.Text.Whitespace']:\n",
    "            \n",
    "            # start with useful nodes: e.g. '1','4','7','9'\n",
    "            if f'{i}' in replace:\n",
    "                value = f'{node_id}.{i}' \n",
    "                cnodes_.append(value)\n",
    "                if colors != []:\n",
    "                    colors_.append(colors[i]) \n",
    "                \n",
    "            elif (f'{i}' in ignore): # 4 is in ignore\n",
    "                \n",
    "                if (f'{last_i}' not in ignore): # 1 is not in ignore\n",
    "                    value = '...'\n",
    "                    cnodes_.append(value)\n",
    "                    if colors != []:\n",
    "                        colors_.append(colors[i])\n",
    "                \n",
    "            else: \n",
    "                value = n.value if len(n.value) <= 200 else n.value[:100] + '\\n...\\n' + n.value[-100:]\n",
    "                cnodes_.append(value)\n",
    "                if colors != []:\n",
    "                    colors_.append(colors[i])\n",
    "            \n",
    "            last_i = i\n",
    "                \n",
    "    if comb_word != '':\n",
    "        cnodes_ = comb_item(cnodes_, comb_word) # to deal with color later\n",
    "    \n",
    "    nodes = {} # dict for nodes\n",
    "    nodes['pnode'] = pnode_ # pnode id, e.g. 'N0.1'\n",
    "    nodes['cnodes'] = cnodes_ # list of cnodes text\n",
    "    nodes['colors'] = colors_ # list of colors for each node\n",
    "    return nodes\n",
    "\n",
    "#------------\n",
    "# Helper 98 (used in Main 01, by 99 sql_graph_list)\n",
    "#------------\n",
    "def gen_nodes_list(pl, include_list=[], addl_replace_list=[], attrs=[]):\n",
    "    '''\n",
    "    Generate pnode-cnodes sets for graph\n",
    "    \n",
    "    pl: statement object\n",
    "    input_list: 'input list' from 03 get_nodes_with_text, a list of pnodes, ['N0.1', 'N0.1.1'] etc.\n",
    "    addl_replact_list: ['N0.1', 'N0.1.1'] etc.\n",
    "    attrs: list of var names to focus on\n",
    "    \n",
    "    return list of node lists: \n",
    "        each node list is generated by helper 06 gen_nodes\n",
    "            nodes['pnode'] = pnode_ # pnode id, e.g. 'N0.1'\n",
    "            nodes['cnodes'] = cnodes_ # list of cnodes text\n",
    "            nodes['colors'] = colors # list of colors for each node\n",
    "    '''\n",
    "\n",
    "    output_list = []\n",
    "    sf_nodes = []\n",
    "\n",
    "    for node_id in include_list: #input_list from (03 get nodes by text)\n",
    "                    \n",
    "        cnodes = get_cnodes_list(pl,node_id) # helper 06, cnode['index'] = str(i), cnode['text'] = str(n.value)\n",
    "        \n",
    "        # REPLACE: if cnode in include_list or exclude_list, replace with node_id\n",
    "        replace_list = find_nodes_replace(node_id, cnodes, include_list+addl_replace_list) # helper 09\n",
    "\n",
    "        # IGNORE: LOGIC RE WHAT TO IGNORE, within \"var node\", all cnodes between select and from, except attrs to focus\n",
    "        sf_nodes.extend(find_nodes_between(node_id, cnodes, 'select', 'from')) # helper 07, list of node_id.\n",
    "        \n",
    "        ignore_list = []\n",
    "        if node_id in sf_nodes: # usually all select attrs are in one sf_node\n",
    "            ignore_cnodes = excl_nodes(cnodes, attrs) # helper 08, return list of nodes obj (index, text)\n",
    "            ignore_list = [str(cnode[\"index\"]) for cnode in ignore_cnodes]\n",
    "            \n",
    "        # COLOR:\n",
    "        color_list = []\n",
    "        def has_attrs(attrs, node_text): # check if cnode text has any attr in attrs list\n",
    "            for attr in attrs:\n",
    "                if attr in node_text:\n",
    "                    return True\n",
    "            return False\n",
    "            \n",
    "        if attrs != []:\n",
    "            for cnode in cnodes:\n",
    "                if has_attrs(attrs, cnode['text']):\n",
    "                    color = '#FFAAAA'\n",
    "                elif cnode['text'][:3]=='N0.':\n",
    "                    color = 'lightgrey'\n",
    "                else:\n",
    "                    color = 'white'                \n",
    "                color_list.append(color)\n",
    "        else: # no attr then highlight population\n",
    "            color_list = []\n",
    "\n",
    "        # helper 97 gen_nodes\n",
    "        nodes = gen_nodes(pl,\n",
    "                          node_id,\n",
    "                          replace=replace_list, \n",
    "                          ignore=ignore_list, \n",
    "                          comb_word='', \n",
    "                          colors=color_list,)\n",
    "        output_list.append(nodes)\n",
    "\n",
    "    return output_list\n",
    "\n",
    "#------------\n",
    "# Helper 99 (used in Main)\n",
    "#------------\n",
    "def sql_graph_list(fname, nodes_list):\n",
    "    '''\n",
    "    plot a list of graphs\n",
    "    fname: file name\n",
    "    nodes_list: list of nodes from help 98 gen_nodes_list\n",
    "    '''\n",
    "    \n",
    "    # create main graph\n",
    "    dot = graphviz.Digraph()\n",
    "    \n",
    "    # add subgraphs\n",
    "    for n, nodes in enumerate(nodes_list):\n",
    "\n",
    "        # parse inputs\n",
    "        pnode = nodes['pnode'] # pnode id, e.g. 'N0.1'\n",
    "        cnodes = nodes['cnodes']\n",
    "        colors = nodes['colors']\n",
    "        \n",
    "        # create subgraph\n",
    "        sub = graphviz.Digraph(name=f'cluster_{pnode}') # cannot use pnode, otherwise no sub label\n",
    "        \n",
    "        # Set the label for the subgraph, list the step ids, start from 1\n",
    "        sub.attr(label=f'Step {n+1}: {pnode}')\n",
    "\n",
    "        # Add nodes\n",
    "        sub.attr('node', shape='box')\n",
    "        for i, node in enumerate(cnodes):\n",
    "            if colors != []:\n",
    "                sub.node(f'{pnode}.{i}', label=node, style='filled', fillcolor = colors[i])\n",
    "            else: # quick hack, can get back to lightgrey\n",
    "                temp = ['N0.', 'whe', 'tba']\n",
    "                sub.node(f'{pnode}.{i}', label=node, style='filled', fillcolor='#FFAAAA' if (node[:3] in temp or node[:1]=='(') else 'white')\n",
    "\n",
    "        # Add edges between nodes\n",
    "        for i in range(len(cnodes)-1):\n",
    "            sub.edge(f'{pnode}.{i}', f'{pnode}.{i+1}', constraint='true')\n",
    "            \n",
    "        # Add the subgraph to the main graph\n",
    "        dot.subgraph(sub)\n",
    "\n",
    "    # Render the graph\n",
    "    dot.render(fname, format='svg', view=True) #png\n",
    "    \n",
    "    return dot\n",
    "\n",
    "#----------\n",
    "# Main 01\n",
    "#----------\n",
    "def audit_graph(fname, query, attrs=[], include_nodes=[], exclude_nodes=[],replace_nodes=[]):\n",
    "    '''\n",
    "    Args:\n",
    "        query: A string that specifies the query.\n",
    "        focus: pop or var\n",
    "        include_nodes: A list of strings that specifies the nodes to include in the results.\n",
    "        exclude_nodes: A list of strings that specifies the nodes to exclude from the results.\n",
    "        replace_nodes: by default, if exclude, node will be flatten and show text.. \n",
    "                       unless in replace_nodes\n",
    "    Returns:\n",
    "        audit_graph.\n",
    "    '''\n",
    "    \n",
    "    # ----------------\n",
    "    # 01. Get SQL_Tree\n",
    "    # ----------------\n",
    "    \n",
    "    pl = gen_pl(query)\n",
    "    print(f'01. pl: {pl}')\n",
    "\n",
    "    # Check if the file exists\n",
    "    # TODO: handle sql_t\n",
    "    if os.path.exists('sql_bt_dl.xlsx'):\n",
    "        # If it exists, read it into a DataFrame\n",
    "        df = pd.read_excel('sql_bt_dl.xlsx')\n",
    "        print(f'01. File sql_bt_dl.xlsx loaded into df.')\n",
    "    else:\n",
    "        # If the file doesn't exist, run the sql2tree function\n",
    "        df = sql2tree(pl)\n",
    "        print(f'01. df = sql2tree(pl): done')\n",
    "        # Save the DataFrame to an Excel file\n",
    "        df.to_excel('sql_bt_dl.xlsx', index=False)\n",
    "    \n",
    "    # ----------------\n",
    "    # 02. Get critical path\n",
    "    # ----------------\n",
    "    \n",
    "    from_nodes = get_from_nodes(pl) # helper 03A, not working for test\n",
    "    print(f'02. from nodes: {from_nodes}')\n",
    "\n",
    "    attrs_nodes = get_nodes_with_text(df,attrs) # helper 03B\n",
    "    print(f'02. attrs_nodes: {attrs_nodes}')\n",
    "    \n",
    "    critical_nodes = sorted(list(set(from_nodes + attrs_nodes)))\n",
    "    print(f'02. critical_nodes: {critical_nodes}')\n",
    "    \n",
    "    post_excl_nodes = excl_steps(critical_nodes, exclude_nodes) # helper 10\n",
    "    print(f'02. post_excl_nodes: {post_excl_nodes}')\n",
    "    \n",
    "    # ----------------\n",
    "    # 03. Get audit graph for all steps on critical path\n",
    "    # ----------------\n",
    "    \n",
    "    nodes_list = gen_nodes_list(pl,post_excl_nodes,replace_nodes,attrs) # helper 98\n",
    "    \n",
    "    g = sql_graph_list(fname, nodes_list) # helper 99\n",
    "    \n",
    "    return g\n",
    "\n",
    "#-------------\n",
    "# Call Main 01\n",
    "#-------------\n",
    "sql_t = '''\n",
    "select \n",
    "var1, \n",
    "abs(var7) as var2, \n",
    "var3 \n",
    "from \n",
    "(select var4, var5, var6 from source)\n",
    "'''\n",
    "\n",
    "\n",
    "'''g = audit_graph(fname = 'Test',\n",
    "                query = sql_t,\n",
    "                attrs = ['var2'],\n",
    "                exclude_nodes = [],) # 'N0.0.4.5'\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3410acb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d6129336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01. pl: <__main__.MyStmts object at 0x7fd307727100>\n",
      "01. File sql_bt_dl.xlsx loaded into df.\n",
      "02. from nodes: ['N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7']\n",
      "02. attrs_nodes: ['N0.0', 'N0.0.7', 'N0.0.7.4', 'N0.0.7.4.62', 'N0.0.7.4.62.4']\n",
      "02. critical_nodes: ['N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0.7.4', 'N0.0.7.4.62', 'N0.0.7.4.62.4']\n",
      "02. post_excl_nodes: ['N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0.7.4', 'N0.0.7.4.62', 'N0.0.7.4.62.4']\n"
     ]
    }
   ],
   "source": [
    "var = 'Prin_Bal_at_Correct_Repay_Start_Dt'\n",
    "\n",
    "g = audit_graph(fname = f'BT_LMR_{var}',\n",
    "                query = sql_bt,\n",
    "                attrs = [var],\n",
    "                exclude_nodes = ['N0.0.7.10.7.0'], # do not show as a node in diagram 'N0.0.7.4'\n",
    "                replace_nodes = ['N0.0.7.4'],\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3d8b17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e4cf4d91",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01. pl: <__main__.MyStmts object at 0x7fd30906d730>\n",
      "01. File sql_bt_dl.xlsx loaded into df.\n",
      "02. from nodes: ['N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7']\n",
      "02. attrs_nodes: ['N0.0', 'N0.0.7', 'N0.0.7.4', 'N0.0.7.4.67', 'N0.0.7.4.67.4']\n",
      "02. critical_nodes: ['N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0.7.4', 'N0.0.7.4.67', 'N0.0.7.4.67.4']\n",
      "02. post_excl_nodes: ['N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0.7.4', 'N0.0.7.4.67', 'N0.0.7.4.67.4']\n"
     ]
    }
   ],
   "source": [
    "var = 'International_Student_Ind'\n",
    "\n",
    "g = audit_graph(fname = f'BT_LMR_{var}',\n",
    "                query = sql_bt,\n",
    "                attrs = [var],\n",
    "                exclude_nodes = ['N0.0.7.10.7.0'], # do not show as a node in diagram 'N0.0.7.4'\n",
    "                replace_nodes = ['N0.0.7.4'],\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d222fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e2c2dc8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['UNIQUE_KEY', 'FORACID', 'ACID', 'Borrower_CIF', 'Cosigner_CIF', 'Current_Ln_Status', 'Correct_Repay_Start_Dt', 'Incorrect_Repay_Start_Dt', 'Impact_Start_Dt', 'Ln_Status_at_Correct_Repay_Start_Dt', 'Dt_of_Last_Interest_Accrual', 'Interest_Accrued_During_Period', 'Highest_Interest_Rate', 'Prin_Bal_at_Correct_Repay_Start_Dt', 'International_Student_Ind', 'Ln_Orig_from', 'TED_Dt', 'Run_Dt', 'Current_Ln_Bal']\n",
      "01. pl: <__main__.MyStmts object at 0x7fd308fe7340>\n",
      "01. File sql_bt_dl.xlsx loaded into df.\n",
      "02. from nodes: ['N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7']\n",
      "02. attrs_nodes: ['N0.0', 'N0.0.7', 'N0.0.7.4', 'N0.0.7.4.0', 'N0.0.7.4.0.4']\n",
      "02. critical_nodes: ['N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0.7.4', 'N0.0.7.4.0', 'N0.0.7.4.0.4']\n",
      "02. post_excl_nodes: ['N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0.7.4', 'N0.0.7.4.0', 'N0.0.7.4.0.4']\n",
      "01. pl: <__main__.MyStmts object at 0x7fd30634cd30>\n",
      "01. File sql_bt_dl.xlsx loaded into df.\n",
      "02. from nodes: ['N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7']\n",
      "02. attrs_nodes: ['N0.0', 'N0.0.7', 'N0.0.7.4', 'N0.0.7.4.4', 'N0.0.7.4.4.6']\n",
      "02. critical_nodes: ['N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0.7.4', 'N0.0.7.4.4', 'N0.0.7.4.4.6']\n",
      "02. post_excl_nodes: ['N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0.7.4', 'N0.0.7.4.4', 'N0.0.7.4.4.6']\n",
      "01. pl: <__main__.MyStmts object at 0x7fd309e3b340>\n",
      "01. File sql_bt_dl.xlsx loaded into df.\n",
      "02. from nodes: ['N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7']\n",
      "02. attrs_nodes: ['N0.0', 'N0.0.7', 'N0.0.7.4', 'N0.0.7.4.4', 'N0.0.7.4.4.6', 'N0.0.7.4.7', 'N0.0.7.4.7.6']\n",
      "02. critical_nodes: ['N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0.7.4', 'N0.0.7.4.4', 'N0.0.7.4.4.6', 'N0.0.7.4.7', 'N0.0.7.4.7.6']\n",
      "02. post_excl_nodes: ['N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0.7.4', 'N0.0.7.4.4', 'N0.0.7.4.4.6', 'N0.0.7.4.7', 'N0.0.7.4.7.6']\n",
      "01. pl: <__main__.MyStmts object at 0x7fd309e1a4f0>\n",
      "01. File sql_bt_dl.xlsx loaded into df.\n",
      "02. from nodes: ['N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7']\n",
      "02. attrs_nodes: ['N0.0', 'N0.0.7', 'N0.0.7.4', 'N0.0.7.4.10', 'N0.0.7.4.10.6']\n",
      "02. critical_nodes: ['N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0.7.4', 'N0.0.7.4.10', 'N0.0.7.4.10.6']\n",
      "02. post_excl_nodes: ['N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0.7.4', 'N0.0.7.4.10', 'N0.0.7.4.10.6']\n",
      "01. pl: <__main__.MyStmts object at 0x7fd308fe7340>\n",
      "01. File sql_bt_dl.xlsx loaded into df.\n",
      "02. from nodes: ['N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7']\n",
      "02. attrs_nodes: ['N0.0', 'N0.0.7', 'N0.0.7.4', 'N0.0.7.4.15', 'N0.0.7.4.15.4']\n",
      "02. critical_nodes: ['N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0.7.4', 'N0.0.7.4.15', 'N0.0.7.4.15.4']\n",
      "02. post_excl_nodes: ['N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0.7.4', 'N0.0.7.4.15', 'N0.0.7.4.15.4']\n",
      "01. pl: <__main__.MyStmts object at 0x7fd308e59850>\n",
      "01. File sql_bt_dl.xlsx loaded into df.\n",
      "02. from nodes: ['N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7']\n",
      "02. attrs_nodes: ['N0.0', 'N0.0.7', 'N0.0.7.4', 'N0.0.7.4.20', 'N0.0.7.4.20.4']\n",
      "02. critical_nodes: ['N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0.7.4', 'N0.0.7.4.20', 'N0.0.7.4.20.4']\n",
      "02. post_excl_nodes: ['N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0.7.4', 'N0.0.7.4.20', 'N0.0.7.4.20.4']\n",
      "01. pl: <__main__.MyStmts object at 0x7fd3075917c0>\n",
      "01. File sql_bt_dl.xlsx loaded into df.\n",
      "02. from nodes: ['N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7']\n",
      "02. attrs_nodes: ['N0.0', 'N0.0.7', 'N0.0.7.4', 'N0.0.7.4.25', 'N0.0.7.4.25.4', 'N0.0.7.4.41', 'N0.0.7.4.41.4', 'N0.0.7.4.62', 'N0.0.7.4.62.4']\n",
      "02. critical_nodes: ['N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0.7.4', 'N0.0.7.4.25', 'N0.0.7.4.25.4', 'N0.0.7.4.41', 'N0.0.7.4.41.4', 'N0.0.7.4.62', 'N0.0.7.4.62.4']\n",
      "02. post_excl_nodes: ['N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0.7.4', 'N0.0.7.4.25', 'N0.0.7.4.25.4', 'N0.0.7.4.41', 'N0.0.7.4.41.4', 'N0.0.7.4.62', 'N0.0.7.4.62.4']\n",
      "01. pl: <__main__.MyStmts object at 0x7fd308fe3400>\n",
      "01. File sql_bt_dl.xlsx loaded into df.\n",
      "02. from nodes: ['N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7']\n",
      "02. attrs_nodes: ['N0.0', 'N0.0.7', 'N0.0.7.4', 'N0.0.7.4.31', 'N0.0.7.4.31.4']\n",
      "02. critical_nodes: ['N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0.7.4', 'N0.0.7.4.31', 'N0.0.7.4.31.4']\n",
      "02. post_excl_nodes: ['N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0.7.4', 'N0.0.7.4.31', 'N0.0.7.4.31.4']\n",
      "01. pl: <__main__.MyStmts object at 0x7fd309e3b340>\n",
      "01. File sql_bt_dl.xlsx loaded into df.\n",
      "02. from nodes: ['N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7']\n",
      "02. attrs_nodes: ['N0.0', 'N0.0.7', 'N0.0.7.4', 'N0.0.7.4.36', 'N0.0.7.4.36.4']\n",
      "02. critical_nodes: ['N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0.7.4', 'N0.0.7.4.36', 'N0.0.7.4.36.4']\n",
      "02. post_excl_nodes: ['N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0.7.4', 'N0.0.7.4.36', 'N0.0.7.4.36.4']\n",
      "01. pl: <__main__.MyStmts object at 0x7fd3077130d0>\n",
      "01. File sql_bt_dl.xlsx loaded into df.\n",
      "02. from nodes: ['N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7']\n",
      "02. attrs_nodes: ['N0.0', 'N0.0.7', 'N0.0.7.4', 'N0.0.7.4.41', 'N0.0.7.4.41.4']\n",
      "02. critical_nodes: ['N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0.7.4', 'N0.0.7.4.41', 'N0.0.7.4.41.4']\n",
      "02. post_excl_nodes: ['N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0.7.4', 'N0.0.7.4.41', 'N0.0.7.4.41.4']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01. pl: <__main__.MyStmts object at 0x7fd309037160>\n",
      "01. File sql_bt_dl.xlsx loaded into df.\n",
      "02. from nodes: ['N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7']\n",
      "02. attrs_nodes: ['N0.0', 'N0.0.7', 'N0.0.7.4', 'N0.0.7.4.47', 'N0.0.7.4.47.4']\n",
      "02. critical_nodes: ['N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0.7.4', 'N0.0.7.4.47', 'N0.0.7.4.47.4']\n",
      "02. post_excl_nodes: ['N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0.7.4', 'N0.0.7.4.47', 'N0.0.7.4.47.4']\n",
      "01. pl: <__main__.MyStmts object at 0x7fd309e03dc0>\n",
      "01. File sql_bt_dl.xlsx loaded into df.\n",
      "02. from nodes: ['N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7']\n",
      "02. attrs_nodes: ['N0.0', 'N0.0.7', 'N0.0.7.4', 'N0.0.7.4.52', 'N0.0.7.4.52.8']\n",
      "02. critical_nodes: ['N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0.7.4', 'N0.0.7.4.52', 'N0.0.7.4.52.8']\n",
      "02. post_excl_nodes: ['N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0.7.4', 'N0.0.7.4.52', 'N0.0.7.4.52.8']\n",
      "01. pl: <__main__.MyStmts object at 0x7fd309e3b340>\n",
      "01. File sql_bt_dl.xlsx loaded into df.\n",
      "02. from nodes: ['N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7']\n",
      "02. attrs_nodes: ['N0.0', 'N0.0.7', 'N0.0.7.4', 'N0.0.7.4.57', 'N0.0.7.4.57.4']\n",
      "02. critical_nodes: ['N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0.7.4', 'N0.0.7.4.57', 'N0.0.7.4.57.4']\n",
      "02. post_excl_nodes: ['N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0.7.4', 'N0.0.7.4.57', 'N0.0.7.4.57.4']\n",
      "01. pl: <__main__.MyStmts object at 0x7fd308fe9df0>\n",
      "01. File sql_bt_dl.xlsx loaded into df.\n",
      "02. from nodes: ['N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7']\n",
      "02. attrs_nodes: ['N0.0', 'N0.0.7', 'N0.0.7.4', 'N0.0.7.4.62', 'N0.0.7.4.62.4']\n",
      "02. critical_nodes: ['N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0.7.4', 'N0.0.7.4.62', 'N0.0.7.4.62.4']\n",
      "02. post_excl_nodes: ['N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0.7.4', 'N0.0.7.4.62', 'N0.0.7.4.62.4']\n",
      "01. pl: <__main__.MyStmts object at 0x7fd308fee610>\n",
      "01. File sql_bt_dl.xlsx loaded into df.\n",
      "02. from nodes: ['N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7']\n",
      "02. attrs_nodes: ['N0.0', 'N0.0.7', 'N0.0.7.4', 'N0.0.7.4.67', 'N0.0.7.4.67.4']\n",
      "02. critical_nodes: ['N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0.7.4', 'N0.0.7.4.67', 'N0.0.7.4.67.4']\n",
      "02. post_excl_nodes: ['N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0.7.4', 'N0.0.7.4.67', 'N0.0.7.4.67.4']\n",
      "01. pl: <__main__.MyStmts object at 0x7fd308fee610>\n",
      "01. File sql_bt_dl.xlsx loaded into df.\n",
      "02. from nodes: ['N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7']\n",
      "02. attrs_nodes: ['N0.0', 'N0.0.7', 'N0.0.7.4', 'N0.0.7.4.72', 'N0.0.7.4.72.4']\n",
      "02. critical_nodes: ['N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0.7.4', 'N0.0.7.4.72', 'N0.0.7.4.72.4']\n",
      "02. post_excl_nodes: ['N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0.7.4', 'N0.0.7.4.72', 'N0.0.7.4.72.4']\n",
      "01. pl: <__main__.MyStmts object at 0x7fd307713490>\n",
      "01. File sql_bt_dl.xlsx loaded into df.\n",
      "02. from nodes: ['N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7']\n",
      "02. attrs_nodes: ['N0.0', 'N0.0.7', 'N0.0.7.4', 'N0.0.7.4.77', 'N0.0.7.4.77.4']\n",
      "02. critical_nodes: ['N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0.7.4', 'N0.0.7.4.77', 'N0.0.7.4.77.4']\n",
      "02. post_excl_nodes: ['N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0.7.4', 'N0.0.7.4.77', 'N0.0.7.4.77.4']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01. pl: <__main__.MyStmts object at 0x7fd30836ac70>\n",
      "01. File sql_bt_dl.xlsx loaded into df.\n",
      "02. from nodes: ['N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7']\n",
      "02. attrs_nodes: ['N0.0', 'N0.0.7', 'N0.0.7.4', 'N0.0.7.4.81', 'N0.0.7.4.81.4']\n",
      "02. critical_nodes: ['N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0.7.4', 'N0.0.7.4.81', 'N0.0.7.4.81.4']\n",
      "02. post_excl_nodes: ['N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0.7.4', 'N0.0.7.4.81', 'N0.0.7.4.81.4']\n",
      "01. pl: <__main__.MyStmts object at 0x7fd308fee610>\n",
      "01. File sql_bt_dl.xlsx loaded into df.\n",
      "02. from nodes: ['N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7']\n",
      "02. attrs_nodes: ['N0.0', 'N0.0.7', 'N0.0.7.4', 'N0.0.7.4.85', 'N0.0.7.4.85.4']\n",
      "02. critical_nodes: ['N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0.7.4', 'N0.0.7.4.85', 'N0.0.7.4.85.4']\n",
      "02. post_excl_nodes: ['N0.0', 'N0.0.7', 'N0.0.7.10', 'N0.0.7.10.7', 'N0.0.7.4', 'N0.0.7.4.85', 'N0.0.7.4.85.4']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def read_column_from_excel(file_path, sheet_name, column_name):\n",
    "    # Read the Excel file\n",
    "    df = pd.read_excel(file_path, sheet_name=sheet_name, engine='openpyxl')\n",
    "    \n",
    "    # Extract the column data into a list\n",
    "    column_data = df[column_name].tolist()\n",
    "    \n",
    "    return column_data\n",
    "\n",
    "# Test the function\n",
    "file_path = 'FW_ Sample Data, BT Calc vs. SF Challenger Query./BT_Calc_Data_CIRT256_20221018_LMR.xlsx'\n",
    "sheet_name = 'Field Explanation - LMR'  # Change to your sheet name if different\n",
    "column_name = 'Field'  # Change to the desired column name\n",
    "fields = read_column_from_excel(file_path, sheet_name, column_name)\n",
    "print(fields)\n",
    "\n",
    "for f in fields:\n",
    "    g = audit_graph(fname = f'BT_LMR_{f}',\n",
    "                query = sql_bt,\n",
    "                attrs = [f],\n",
    "                exclude_nodes = ['N0.0.7.10.7.0'], # do not show as a node in diagram 'N0.0.7.4'\n",
    "                replace_nodes = ['N0.0.7.4'],\n",
    "               )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0438e54e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc4bf55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: debug no attr.. maybe add input for user to force red nodes\n",
    "g = audit_graph(fname = 'BT_LMR',\n",
    "                query = sql_bt,\n",
    "                attrs = [],\n",
    "                exclude_nodes = ['N0.0.7.10.7.0','N0.0.7.4'], # do not show as a node in diagram 'N0.0.7.4'\n",
    "                replace_nodes = ['N0.0.7.4'],\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8f2163",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16825482",
   "metadata": {},
   "outputs": [],
   "source": [
    "#BACKUP \n",
    "\n",
    "g = audit_graph(fname = 'BT_LMR',\n",
    "                query = sql_bt,\n",
    "                attrs = ['Prin_Bal_at_Correct_Repay_Start_Dt'],\n",
    "                exclude_nodes = ['N0.0.7.10.7.0',], # 'N0.0.7.4'\n",
    "                replace_nodes = [])\n",
    "\n",
    "#------------\n",
    "# Helper 03 (used by Main 01)\n",
    "#------------\n",
    "def get_nodes_with_text(df, include_list):\n",
    "    \n",
    "    cond1 = df['Node_ID'] != 'N0' # remove top level, which is a extra level to handle multiple statements\n",
    "    cond2 = df['Value'].str.contains('|'.join(include_list)) # contains keywords\n",
    "    cond3 = df['Type']=='None' # only plot nodes with children\n",
    "    \n",
    "    result = df[cond1 & cond2 & cond3]['Node_ID'].to_list()\n",
    "    \n",
    "    return result # list of node_ids (input_list) for 07 nodes_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6fb1ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b825601b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef74b897",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Node_ID</th>\n",
       "      <th>Type</th>\n",
       "      <th>Lines</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>N0</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>\\nselect * from (\\nselect gam.acid||to_char(st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>N0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>596.0</td>\n",
       "      <td>\\nselect * from (\\nselect gam.acid||to_char(...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>N0.0.0</td>\n",
       "      <td>Token.Text.Whitespace.Newline</td>\n",
       "      <td>1.0</td>\n",
       "      <td>\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>N0.0.1</td>\n",
       "      <td>Token.Keyword.DML</td>\n",
       "      <td>1.0</td>\n",
       "      <td>select</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>N0.0.2</td>\n",
       "      <td>Token.Text.Whitespace</td>\n",
       "      <td>1.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5838</th>\n",
       "      <td>N0.0.7.12.6.2</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>lam.acid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5839</th>\n",
       "      <td>N0.0.7.12.6.2.0</td>\n",
       "      <td>Token.Name</td>\n",
       "      <td>1.0</td>\n",
       "      <td>lam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5840</th>\n",
       "      <td>N0.0.7.12.6.2.1</td>\n",
       "      <td>Token.Punctuation</td>\n",
       "      <td>1.0</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5841</th>\n",
       "      <td>N0.0.7.12.6.2.2</td>\n",
       "      <td>Token.Name</td>\n",
       "      <td>1.0</td>\n",
       "      <td>acid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5842</th>\n",
       "      <td>N0.0.7.13</td>\n",
       "      <td>Token.Punctuation</td>\n",
       "      <td>1.0</td>\n",
       "      <td>)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5843 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Node_ID                           Type  Lines  \\\n",
       "0                  N0                           None    1.0   \n",
       "1                N0.0                           None  596.0   \n",
       "2              N0.0.0  Token.Text.Whitespace.Newline    1.0   \n",
       "3              N0.0.1              Token.Keyword.DML    1.0   \n",
       "4              N0.0.2          Token.Text.Whitespace    1.0   \n",
       "...               ...                            ...    ...   \n",
       "5838    N0.0.7.12.6.2                           None    1.0   \n",
       "5839  N0.0.7.12.6.2.0                     Token.Name    1.0   \n",
       "5840  N0.0.7.12.6.2.1              Token.Punctuation    1.0   \n",
       "5841  N0.0.7.12.6.2.2                     Token.Name    1.0   \n",
       "5842        N0.0.7.13              Token.Punctuation    1.0   \n",
       "\n",
       "                                                  Value  \n",
       "0     \\nselect * from (\\nselect gam.acid||to_char(st...  \n",
       "1       \\nselect * from (\\nselect gam.acid||to_char(...  \n",
       "2                                                    \\n  \n",
       "3                                                select  \n",
       "4                                                        \n",
       "...                                                 ...  \n",
       "5838                                           lam.acid  \n",
       "5839                                                lam  \n",
       "5840                                                  .  \n",
       "5841                                               acid  \n",
       "5842                                                  )  \n",
       "\n",
       "[5843 rows x 4 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 00. read in sql string (see bottom)\n",
    "# 01. gen sql_tree\n",
    "\n",
    "import sqlparse\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# 01. gen sql_tree\n",
    "def sql2tree(node, pnode_id='', local_node_id = 0, df = pd.DataFrame()):\n",
    "    if node is None:\n",
    "        return\n",
    "    \n",
    "    node_id = 'N0' if pnode_id=='' else f'{pnode_id}.{local_node_id}'\n",
    "    ntype = str(node.ttype)\n",
    "    Lines = len(str(node).splitlines())\n",
    "    value = '  ' * node_id.count('.') + str(node.value) # add indentation\n",
    "    \n",
    "    new_row = pd.Series({'Node_ID': node_id, 'Type': ntype, 'Lines': Lines, 'Value': value,})\n",
    "\n",
    "    df = df.append(new_row, ignore_index=True)\n",
    "    \n",
    "    if node.ttype is None :\n",
    "        for i, child in enumerate(node.tokens):\n",
    "            df = sql2tree(child, node_id, i, df) # index start from 0\n",
    "            \n",
    "    return df\n",
    "\n",
    "class MyStmts:\n",
    "    def __init__(self):\n",
    "        self.tokens = []\n",
    "        self.ttype = None\n",
    "        self.value = ''\n",
    "\n",
    "df_q = pd.DataFrame()\n",
    "\n",
    "# USE sql_bt INPUT QUERY\n",
    "\n",
    "df_q.at[0, 'QUERY_TEXT'] = sql_bt # assign sql text to df cell\n",
    "pl = MyStmts()\n",
    "\n",
    "for index, row in df_q.iterrows(): #multiple queries in SF\n",
    "    sql = row['QUERY_TEXT']\n",
    "    sql = re.sub(r'--.*', '', sql) # remove comment\n",
    "    sql = sql.replace(\",\", \",\\n\") # break commas\n",
    "    parsed = sqlparse.parse(sql) \n",
    "    root = parsed[0]\n",
    "    pl.tokens.append(root)\n",
    "    pl.value += row['QUERY_TEXT'] + \"\\n\"\n",
    "    \n",
    "df = sql2tree(pl)\n",
    "    \n",
    "import xlwings as xw\n",
    "wb = xw.Book('bt_lmr_sql_tree.xlsx')\n",
    "sh = wb.sheets[0]\n",
    "sh.clear_contents()\n",
    "sh.range('A1').value = df\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0eb4a408",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Lines</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Node_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>N0</th>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>\\nselect * from (\\nselect gam.acid||to_char(st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N0.0</th>\n",
       "      <td>None</td>\n",
       "      <td>596.0</td>\n",
       "      <td>\\nselect * from (\\nselect gam.acid||to_char(...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N0.0.1</th>\n",
       "      <td>Token.Keyword.DML</td>\n",
       "      <td>1.0</td>\n",
       "      <td>select</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N0.0.3</th>\n",
       "      <td>Token.Wildcard</td>\n",
       "      <td>1.0</td>\n",
       "      <td>*</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N0.0.5</th>\n",
       "      <td>Token.Keyword</td>\n",
       "      <td>1.0</td>\n",
       "      <td>from</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N0.0.7.12.6.0.2</th>\n",
       "      <td>Token.Name</td>\n",
       "      <td>1.0</td>\n",
       "      <td>acid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N0.0.7.12.6.1</th>\n",
       "      <td>Token.Operator.Comparison</td>\n",
       "      <td>1.0</td>\n",
       "      <td>=</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N0.0.7.12.6.2</th>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>lam.acid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N0.0.7.12.6.2.0</th>\n",
       "      <td>Token.Name</td>\n",
       "      <td>1.0</td>\n",
       "      <td>lam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N0.0.7.12.6.2.2</th>\n",
       "      <td>Token.Name</td>\n",
       "      <td>1.0</td>\n",
       "      <td>acid</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3391 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Type  Lines  \\\n",
       "Node_ID                                             \n",
       "N0                                    None    1.0   \n",
       "N0.0                                  None  596.0   \n",
       "N0.0.1                   Token.Keyword.DML    1.0   \n",
       "N0.0.3                      Token.Wildcard    1.0   \n",
       "N0.0.5                       Token.Keyword    1.0   \n",
       "...                                    ...    ...   \n",
       "N0.0.7.12.6.0.2                 Token.Name    1.0   \n",
       "N0.0.7.12.6.1    Token.Operator.Comparison    1.0   \n",
       "N0.0.7.12.6.2                         None    1.0   \n",
       "N0.0.7.12.6.2.0                 Token.Name    1.0   \n",
       "N0.0.7.12.6.2.2                 Token.Name    1.0   \n",
       "\n",
       "                                                             Value  \n",
       "Node_ID                                                             \n",
       "N0               \\nselect * from (\\nselect gam.acid||to_char(st...  \n",
       "N0.0               \\nselect * from (\\nselect gam.acid||to_char(...  \n",
       "N0.0.1                                                      select  \n",
       "N0.0.3                                                           *  \n",
       "N0.0.5                                                        from  \n",
       "...                                                            ...  \n",
       "N0.0.7.12.6.0.2                                               acid  \n",
       "N0.0.7.12.6.1                                                    =  \n",
       "N0.0.7.12.6.2                                             lam.acid  \n",
       "N0.0.7.12.6.2.0                                                lam  \n",
       "N0.0.7.12.6.2.2                                               acid  \n",
       "\n",
       "[3391 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dff = df[~df['Type'].isin([\n",
    "    'Token.Text.Whitespace.Newline',\n",
    "    'Token.Punctuation',\n",
    "    'Token.Text.Whitespace'])].set_index('Node_ID')\n",
    "\n",
    "import xlwings as xw\n",
    "wb = xw.Book('bt_lmr_sql_tree_DL.xlsm')\n",
    "sh = wb.sheets[0]\n",
    "sh.clear_contents()\n",
    "sh.range('A1').value = dff\n",
    "\n",
    "dff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d15476fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz\n",
    "\n",
    "def getNodebyID(s, node_id):\n",
    "    ids = node_id.split('.')\n",
    "    s = s.tokens # handle first 0\n",
    "    ids = ids[1:]\n",
    "    for i in ids:\n",
    "        s = s[int(i)]\n",
    "    return s\n",
    "\n",
    "def comb_item(my_list, word):\n",
    "    new_list = []\n",
    "\n",
    "    i = 0\n",
    "    while i < len(my_list):\n",
    "        if my_list[i] == word and i < len(my_list) - 1:\n",
    "            new_string = f'{my_list[i]} {my_list[i + 1]}'\n",
    "            new_list.append(new_string)\n",
    "            i += 2\n",
    "        else:\n",
    "            new_list.append(my_list[i])\n",
    "            i += 1\n",
    "    return new_list\n",
    "\n",
    "def gen_nodes(s, node_id, replace=[], ignore=[], comb_word='', colors=[]):\n",
    "\n",
    "    # pnode label\n",
    "    pnode_ = f'N{node_id}'\n",
    "    \n",
    "    # cnodes labels\n",
    "    pnode = getNodebyID(pl,node_id)\n",
    "    cnodes_ = []\n",
    "    \n",
    "    for i, n in enumerate(pnode.tokens):\n",
    "        \n",
    "        if str(n.ttype) not in [\n",
    "            'Token.Text.Whitespace.Newline',\n",
    "            'Token.Punctuation',\n",
    "            'Token.Text.Whitespace']:\n",
    "\n",
    "            if f'{i}' in replace:\n",
    "                value = f'N{node_id}.{i}' \n",
    "                cnodes_.append(value)\n",
    "                \n",
    "            elif (f'{i}' in ignore):\n",
    "                if (f'{i-1}' not in ignore):\n",
    "                    value = '...'\n",
    "                    cnodes_.append(value)\n",
    "                \n",
    "            else: \n",
    "                value = n.value\n",
    "                cnodes_.append(value)\n",
    "                \n",
    "    if comb_word != '':\n",
    "        cnodes_ = comb_item(cnodes_, comb_word)\n",
    "    \n",
    "    nodes = {} # dict for nodes\n",
    "    nodes['pnode'] = pnode_\n",
    "    nodes['cnodes'] = cnodes_\n",
    "    nodes['colors'] = colors\n",
    "    return nodes\n",
    "\n",
    "\n",
    "def sql_graph_list(fname, nodes_list):\n",
    "    \n",
    "    # create main graph\n",
    "    dot = graphviz.Digraph()\n",
    "    \n",
    "    # add subgraphs\n",
    "    for nodes in nodes_list:\n",
    "\n",
    "        # parse inputs\n",
    "        pnode = nodes['pnode']\n",
    "        cnodes = nodes['cnodes']\n",
    "        colors = nodes['colors']\n",
    "        \n",
    "        # create subgraph\n",
    "        sub = graphviz.Digraph(name=f'cluster_{pnode}') # cannot use pnode, otherwise no sub label\n",
    "        \n",
    "        # Set the label for the subgraph\n",
    "        sub.attr(label=pnode)\n",
    "\n",
    "        # Add nodes\n",
    "        sub.attr('node', shape='box')\n",
    "        for i, node in enumerate(cnodes):\n",
    "            if colors != []:\n",
    "                sub.node(f'{pnode}.{i}', label=node, style='filled', fillcolor = colors[i])\n",
    "            else:\n",
    "                sub.node(f'{pnode}.{i}', label=node, style='filled', fillcolor='lightgrey' if node[:3]=='N0.' else 'white')\n",
    "\n",
    "        # Add edges between nodes\n",
    "        for i in range(len(cnodes)-1):\n",
    "            sub.edge(f'{pnode}.{i}', f'{pnode}.{i+1}', constraint='true')\n",
    "            \n",
    "        # Add the subgraph to the main graph\n",
    "        dot.subgraph(sub)\n",
    "\n",
    "    # Render the graph\n",
    "    dot.render(fname, format='png', view=True)\n",
    "\n",
    "nodes_list = [\n",
    "    gen_nodes(pl,'0.0',['7']),\n",
    "    gen_nodes(pl,'0.0.7',['4','10']),\n",
    "    gen_nodes(pl,'0.0.7.4',['62'],[f'{i}' for i in list(range(0,62))+list(range(67,86))]),\n",
    "    gen_nodes(pl,'0.0.7.4.62',['0'],[],'',['lightgrey']+['white']+['#FFAAAA']),\n",
    "    gen_nodes(pl,'0.0.7.4.62.0',[],[],'',['white','#FFAAAA']*2+['white']),\n",
    "    gen_nodes(pl,'0.0.7.10',['7'],),\n",
    "    \n",
    "]\n",
    "sql_graph_list('BT_LMR', nodes_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146d78d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1762e8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# backup\n",
    "    gen_nodes(pl,'0.0.7',['0']),\n",
    "    gen_nodes(pl,'0.0.7.0',['7']),\n",
    "    gen_nodes(pl,'0.0.7.0.7',['61'],[f'{i}' for i in list(range(4,57))]),\n",
    "    gen_nodes(pl,'0.0.7.0.7.61',['0']),\n",
    "    gen_nodes(pl,'0.0.7.0.7.61.0',['12'],['5']),\n",
    "    gen_nodes(pl,'0.0.7.0.7.61.0.12',['0'],),\n",
    "    gen_nodes(pl,'0.0.7.0.7.61.0.12.0',['11','13'],[f'{i}' for i in list(range(4,7))]),\n",
    "    gen_nodes(pl,'0.0.7.0.7.61.0.12.0.11',['10'],),\n",
    "    gen_nodes(pl,'0.0.7.0.7.61.0.12.0.13',[],[],'and', ['white']*4+['#FFAAAA']*4+['white']*2+['#FFAAAA']*2),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051f1c30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "be5505d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "290f2f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_bt = '''\n",
    "select * from (\n",
    "select gam.acid||to_char(start_date,'MMDDYYYY')||to_char(end_date,'MMDDYYYY') as \"UNIQUE_KEY\",\n",
    "gam.foracid as \"FORACID\",gam.acid as \"ACID\",gam.cif_id as \"Borrower_CIF\",\n",
    "\n",
    "(select nma_key_id from tbaadm.aas where acid=gam.acid and del_flg='N' and acct_poa_as_rec_type='C') as \"Cosigner_CIF\",\n",
    "\n",
    "Decode(Loan_status,'S','In School','H','Holiday Period','G','Grace','R','Repayment','P','Paid Off','X','Closed','W','Charged Off','D','Deferment','F','Forbearance','T','Restructure','I','Disaster Relief','Q','Settlement Pending','K','Write Off','Z','Settled') as \"Current_Ln_Status\",\n",
    "\n",
    "start_date as \"Correct_Repay_Start_Dt\",\n",
    "--end_date as \"Incorrect_Repay_Start_Dt\",end_date as \"Impact_Start_Dt\",\n",
    "\n",
    "(case when loan_status in ('P','Q','W','Z','K')\n",
    "then\n",
    "case when Loan_status in ('P') then least(t.end_date,(select payoff_value_date from tbaadm.port where acid=gam.acid))\n",
    "else\n",
    "least(t.end_date,(select min(chrg_off_date) from tbaadm.la_coht where acid=gam.acid and reversed_flg='N')) end\n",
    "else t.end_date end) as \"Incorrect_Repay_Start_Dt\",\n",
    "\n",
    "(case when loan_status in ('P','Q','W','Z','K')\n",
    "then\n",
    "case when Loan_status in ('P') then least(t.end_date,(select payoff_value_date from tbaadm.port where acid=gam.acid))\n",
    "else\n",
    "least(t.end_date,(select min(chrg_off_date) from tbaadm.la_coht where acid=gam.acid and reversed_flg='N')) end\n",
    "else t.end_date end) as \"Impact_Start_Dt\",\n",
    "\n",
    "Decode(dfscust.dfs_utilities.get_loan_status_post(gam.acid,start_date),'S','In School','H','Holiday Period','G','Grace','R','Repayment','P','Paid Off','X','Closed','W','Charged Off','D','Deferment','F','Forbearance','T','Restructure','I','Disaster Relief','Q','Settlement Pending','K','Write Off','Z','Settled') as \"Ln_Status_at_Correct_Repay_Start_Dt\",\n",
    "\n",
    "\n",
    "case when Loan_status in ('P') then (select payoff_value_date from tbaadm.port where acid=gam.acid)\n",
    "when Loan_status in ('W','K','Q','Z') then \n",
    "(select min(chrg_off_date) from tbaadm.la_coht where acid=gam.acid and reversed_flg='N')\n",
    "else null end as \"Dt_of_Last_Interest_Accrual\",\n",
    "\n",
    "dfscust.dfs_utilities.int_amt_calc(gam.acid,t.start_date,t.end_date) as \"Interest_Accrued_During_Period\",\n",
    "\n",
    "(select max(full_rate) full_rate from tbaadm.idt where entity_id=gam.acid\n",
    "and (idt.start_date between (case when loan_status in ('P','Q','W','Z','K')\n",
    "then\n",
    "case when Loan_status in ('P') then least(t.end_date,(select payoff_value_date-1 from tbaadm.port where acid=gam.acid))\n",
    "else\n",
    "least(t.end_date,(select min(chrg_off_date)-1 from tbaadm.la_coht where acid=gam.acid and reversed_flg='N')) end\n",
    "else t.end_date end)\n",
    "and (select db_stat_date from tbaadm.gct) or\n",
    "((case when loan_status in ('P','Q','W','Z','K')\n",
    "then\n",
    "case when Loan_status in ('P') then least(t.end_date,(select payoff_value_date-1 from tbaadm.port where acid=gam.acid))\n",
    "else\n",
    "least(t.end_date,(select min(chrg_off_date)-1 from tbaadm.la_coht where acid=gam.acid and reversed_flg='N')) end\n",
    "else t.end_date end) between idt.start_date and idt.end_date and\n",
    "(select db_stat_date from tbaadm.gct) between idt.start_date and idt.end_date) or\n",
    "idt.end_date between (case when loan_status in ('P','Q','W','Z','K')\n",
    "then\n",
    "case when Loan_status in ('P') then least(t.end_date,(select payoff_value_date-1 from tbaadm.port where acid=gam.acid))\n",
    "else\n",
    "least(t.end_date,(select min(chrg_off_date)-1 from tbaadm.la_coht where acid=gam.acid and reversed_flg='N')) end\n",
    "else t.end_date end) and (select db_stat_date from tbaadm.gct))) as \"Highest_Interest_Rate\",\n",
    "\n",
    "(select \n",
    "case when value_date_bal >=0 then 0\n",
    "else abs(value_date_bal) end \n",
    "from tbaadm.eab where acid=gam.acid and t.start_date between eod_date and end_eod_date) as \"Prin_Bal_at_Correct_Repay_Start_Dt\",\n",
    "\n",
    "case \n",
    "when (select count(*) from crmuser.taxdetails where orgkey=gam.cif_id and taxidtype in ('PROXY','ITIN','EIN')) >0\n",
    "then 'Y'\n",
    "when (select count(*) from crmuser.taxdetails where orgkey=gam.cif_id and taxidtype='SSN' and substr(taxid,1,1)='9') >0\n",
    "then 'Y' else 'N' end as \"International_Student_Ind\",\n",
    "\n",
    "case when (select to_char(cutover_date,'YYYY') from dfscust.csllaadt where acid=gam.acid) = '2017' then 'Diploma'\n",
    "when (select to_char(cutover_date,'YYYY') from dfscust.csllaadt where acid=gam.acid) = '2018' then 'Great Lakes'\n",
    "else 'Finacle' end as \"Ln_Orig_from\",\n",
    "\n",
    "xfer_eff_date as \"TED_Dt\",\n",
    "(select db_stat_date from tbaadm.gct) as \"Run_Dt\",\n",
    "case when clr_bal_amt >=0 then 0 else abs(clr_bal_amt)+int_dmd_os end as \"Current_Ln_Bal\"\n",
    "\n",
    " from tbaadm.gam,tbaadm.lam,\n",
    "(\n",
    "select 'SM5494538' acid,to_date('16-Nov-2018','DD-MON-YYYY') start_date,to_date('11-May-2019','DD-MON-YYYY') end_date from dual union all\n",
    "select 'SM5540633' acid,to_date('23-Jul-2020','DD-MON-YYYY') start_date,to_date('24-Jul-2020','DD-MON-YYYY') end_date from dual union all\n",
    "select 'SM5540672' acid,to_date('23-Jul-2020','DD-MON-YYYY') start_date,to_date('24-Jul-2020','DD-MON-YYYY') end_date from dual union all\n",
    "select 'SM7857199' acid,to_date('24-Dec-2019','DD-MON-YYYY') start_date,to_date('17-Jun-2020','DD-MON-YYYY') end_date from dual union all\n",
    "select 'SM5701180' acid,to_date('18-Oct-2018','DD-MON-YYYY') start_date,to_date('04-May-2019','DD-MON-YYYY') end_date from dual union all\n",
    "select 'SM5538786' acid,to_date('05-Nov-2020','DD-MON-YYYY') start_date,to_date('06-Nov-2020','DD-MON-YYYY') end_date from dual union all\n",
    "select 'SM5621552' acid,to_date('03-Sep-2020','DD-MON-YYYY') start_date,to_date('04-Sep-2020','DD-MON-YYYY') end_date from dual union all\n",
    "select 'SM5621521' acid,to_date('03-Sep-2020','DD-MON-YYYY') start_date,to_date('04-Sep-2020','DD-MON-YYYY') end_date from dual union all\n",
    "select 'SM5612596' acid,to_date('18-Oct-2018','DD-MON-YYYY') start_date,to_date('15-Dec-2018','DD-MON-YYYY') end_date from dual union all\n",
    "select 'SM5612630' acid,to_date('18-Oct-2018','DD-MON-YYYY') start_date,to_date('15-Dec-2018','DD-MON-YYYY') end_date from dual union all\n",
    "select 'SM5526726' acid,to_date('07-Jul-2020','DD-MON-YYYY') start_date,to_date('22-Dec-2020','DD-MON-YYYY') end_date from dual union all\n",
    "select 'SM5622143' acid,to_date('22-Mar-2018','DD-MON-YYYY') start_date,to_date('23-Sep-2019','DD-MON-YYYY') end_date from dual union all\n",
    "select 'SM5495196' acid,to_date('16-Nov-2018','DD-MON-YYYY') start_date,to_date('10-Aug-2019','DD-MON-YYYY') end_date from dual union all\n",
    "select 'SM5495157' acid,to_date('16-Nov-2018','DD-MON-YYYY') start_date,to_date('10-Aug-2019','DD-MON-YYYY') end_date from dual union all\n",
    "select 'SM5504710' acid,to_date('15-Jul-2020','DD-MON-YYYY') start_date,to_date('17-Jul-2020','DD-MON-YYYY') end_date from dual union all\n",
    "select 'SM5540533' acid,to_date('15-Jun-2020','DD-MON-YYYY') start_date,to_date('23-Jun-2020','DD-MON-YYYY') end_date from dual union all\n",
    "select 'SM5624131' acid,to_date('16-Nov-2018','DD-MON-YYYY') start_date,to_date('21-Dec-2019','DD-MON-YYYY') end_date from dual union all\n",
    "select 'SM5624169' acid,to_date('16-Nov-2018','DD-MON-YYYY') start_date,to_date('21-Dec-2019','DD-MON-YYYY') end_date from dual union all\n",
    "select 'SM6287539' acid,to_date('13-Jan-2021','DD-MON-YYYY') start_date,to_date('15-Jan-2021','DD-MON-YYYY') end_date from dual union all\n",
    "select 'SM5201433' acid,to_date('13-Jan-2021','DD-MON-YYYY') start_date,to_date('15-Jan-2021','DD-MON-YYYY') end_date from dual union all\n",
    "select 'SM5238330' acid,to_date('26-May-2020','DD-MON-YYYY') start_date,to_date('27-Jun-2020','DD-MON-YYYY') end_date from dual union all\n",
    "select 'SM5653801' acid,to_date('08-May-2021','DD-MON-YYYY') start_date,to_date('25-May-2021','DD-MON-YYYY') end_date from dual union all\n",
    "select 'SM5653838' acid,to_date('08-May-2021','DD-MON-YYYY') start_date,to_date('25-May-2021','DD-MON-YYYY') end_date from dual union all\n",
    "select 'SM5490220' acid,to_date('21-Nov-2018','DD-MON-YYYY') start_date,to_date('13-Nov-2022','DD-MON-YYYY') end_date from dual union all\n",
    "select 'SM5494673' acid,to_date('06-Jun-2019','DD-MON-YYYY') start_date,to_date('07-Jun-2019','DD-MON-YYYY') end_date from dual union all\n",
    "select 'SM5483928' acid,to_date('10-Oct-2018','DD-MON-YYYY') start_date,to_date('11-Jan-2019','DD-MON-YYYY') end_date from dual union all\n",
    "select 'SM5483969' acid,to_date('10-Oct-2018','DD-MON-YYYY') start_date,to_date('11-Jan-2019','DD-MON-YYYY') end_date from dual union all\n",
    "select 'SM5200178' acid,to_date('11-May-2021','DD-MON-YYYY') start_date,to_date('13-Nov-2022','DD-MON-YYYY') end_date from dual union all\n",
    "select 'SM5671895' acid,to_date('28-Nov-2018','DD-MON-YYYY') start_date,to_date('18-May-2019','DD-MON-YYYY') end_date from dual union all\n",
    "select 'SM5773779' acid,to_date('28-Nov-2018','DD-MON-YYYY') start_date,to_date('11-May-2020','DD-MON-YYYY') end_date from dual union all\n",
    "select 'SM5794545' acid,to_date('14-Aug-2020','DD-MON-YYYY') start_date,to_date('17-Aug-2020','DD-MON-YYYY') end_date from dual union all\n",
    "select 'SM5794582' acid,to_date('14-Aug-2020','DD-MON-YYYY') start_date,to_date('17-Aug-2020','DD-MON-YYYY') end_date from dual union all\n",
    "select 'SM5820933' acid,to_date('08-Jan-2019','DD-MON-YYYY') start_date,to_date('18-May-2019','DD-MON-YYYY') end_date from dual union all\n",
    "select 'SM5820971' acid,to_date('08-Jan-2019','DD-MON-YYYY') start_date,to_date('18-May-2019','DD-MON-YYYY') end_date from dual union all\n",
    "select 'SM5778886' acid,to_date('26-Dec-2018','DD-MON-YYYY') start_date,to_date('07-Dec-2019','DD-MON-YYYY') end_date from dual union all\n",
    "select 'SM5778923' acid,to_date('26-Dec-2018','DD-MON-YYYY') start_date,to_date('07-Dec-2019','DD-MON-YYYY') end_date from dual union all\n",
    "select 'SM5440518' acid,to_date('15-Jul-2020','DD-MON-YYYY') start_date,to_date('17-Jul-2020','DD-MON-YYYY') end_date from dual union all\n",
    "select 'SM5805656' acid,to_date('16-Jun-2020','DD-MON-YYYY') start_date,to_date('08-Jul-2020','DD-MON-YYYY') end_date from dual union all\n",
    "select 'SM5805736' acid,to_date('16-Jun-2020','DD-MON-YYYY') start_date,to_date('08-Jul-2020','DD-MON-YYYY') end_date from dual union all\n",
    "select 'SM5805695' acid,to_date('16-Jun-2020','DD-MON-YYYY') start_date,to_date('08-Jul-2020','DD-MON-YYYY') end_date from dual union all\n",
    "select 'SM5805778' acid,to_date('16-Jun-2020','DD-MON-YYYY') start_date,to_date('08-Jul-2020','DD-MON-YYYY') end_date from dual union all\n",
    "select 'SM5667576' acid,to_date('10-Jun-2020','DD-MON-YYYY') start_date,to_date('23-Jun-2020','DD-MON-YYYY') end_date from dual union all\n",
    "select 'SM5667538' acid,to_date('10-Jun-2020','DD-MON-YYYY') start_date,to_date('23-Jun-2020','DD-MON-YYYY') end_date from dual union all\n",
    "select 'SM5805303' acid,to_date('08-Jul-2020','DD-MON-YYYY') start_date,to_date('11-Dec-2020','DD-MON-YYYY') end_date from dual union all\n",
    "select 'SM5805341' acid,to_date('08-Jul-2020','DD-MON-YYYY') start_date,to_date('11-Dec-2020','DD-MON-YYYY') end_date from dual union all\n",
    "select 'SM5768190' acid,to_date('17-Oct-2018','DD-MON-YYYY') start_date,to_date('06-Mar-2019','DD-MON-YYYY') end_date from dual union all\n",
    "select 'SM5697114' acid,to_date('23-May-2019','DD-MON-YYYY') start_date,to_date('24-Sep-2019','DD-MON-YYYY') end_date from dual union all\n",
    "select 'SM4596599' acid,to_date('16-Aug-2019','DD-MON-YYYY') start_date,to_date('14-Dec-2019','DD-MON-YYYY') end_date from dual union all\n",
    "select 'SM4596578' acid,to_date('16-Aug-2019','DD-MON-YYYY') start_date,to_date('14-Dec-2019','DD-MON-YYYY') end_date from dual union all\n",
    "select 'SM4772295' acid,to_date('14-Nov-2017','DD-MON-YYYY') start_date,to_date('04-Dec-2017','DD-MON-YYYY') end_date from dual union all\n",
    "select 'SM4514481' acid,to_date('01-Feb-2018','DD-MON-YYYY') start_date,to_date('08-Jun-2019','DD-MON-YYYY') end_date from dual union all\n",
    "select 'SM4514427' acid,to_date('01-Feb-2018','DD-MON-YYYY') start_date,to_date('10-Jul-2021','DD-MON-YYYY') end_date from dual union all\n",
    "select 'SM4514401' acid,to_date('01-Feb-2018','DD-MON-YYYY') start_date,to_date('10-Jul-2021','DD-MON-YYYY') end_date from dual union all\n",
    "select 'SM4514454' acid,to_date('01-Feb-2018','DD-MON-YYYY') start_date,to_date('10-Jul-2021','DD-MON-YYYY') end_date from dual union all\n",
    "select 'SM4531917' acid,to_date('19-Oct-2017','DD-MON-YYYY') start_date,to_date('01-Oct-2020','DD-MON-YYYY') end_date from dual union all\n",
    "select 'SM4752166' acid,to_date('16-Nov-2018','DD-MON-YYYY') start_date,to_date('25-Apr-2019','DD-MON-YYYY') end_date from dual union all\n",
    "select 'SM5866675' acid,to_date('16-Nov-2018','DD-MON-YYYY') start_date,to_date('09-Dec-2019','DD-MON-YYYY') end_date from dual union all\n",
    "select 'SM4747729' acid,to_date('13-Apr-2018','DD-MON-YYYY') start_date,to_date('01-Jul-2019','DD-MON-YYYY') end_date from dual union all\n",
    "select 'SM4424700' acid,to_date('27-Jul-2021','DD-MON-YYYY') start_date,to_date('26-Oct-2021','DD-MON-YYYY') end_date from dual union all\n",
    "select 'SM4424742' acid,to_date('27-Jul-2021','DD-MON-YYYY') start_date,to_date('26-Oct-2021','DD-MON-YYYY') end_date from dual union all\n",
    "select 'SM5865347' acid,to_date('22-Jul-2020','DD-MON-YYYY') start_date,to_date('30-Sep-2020','DD-MON-YYYY') end_date from dual union all\n",
    "select 'SM5865353' acid,to_date('22-Jul-2020','DD-MON-YYYY') start_date,to_date('30-Sep-2020','DD-MON-YYYY') end_date from dual union all\n",
    "select 'SM4563239' acid,to_date('22-Jul-2020','DD-MON-YYYY') start_date,to_date('30-Sep-2020','DD-MON-YYYY') end_date from dual union all\n",
    "select 'SM4585936' acid,to_date('13-Nov-2017','DD-MON-YYYY') start_date,to_date('25-Apr-2018','DD-MON-YYYY') end_date from dual union all\n",
    "select 'SM4585965' acid,to_date('13-Nov-2017','DD-MON-YYYY') start_date,to_date('23-Oct-2018','DD-MON-YYYY') end_date from dual union all\n",
    "select 'SM4586290' acid,to_date('13-Nov-2017','DD-MON-YYYY') start_date,to_date('23-Oct-2018','DD-MON-YYYY') end_date from dual union all\n",
    "select 'SM4586334' acid,to_date('13-Nov-2017','DD-MON-YYYY') start_date,to_date('23-Oct-2018','DD-MON-YYYY') end_date from dual union all\n",
    "select 'SM4586357' acid,to_date('13-Nov-2017','DD-MON-YYYY') start_date,to_date('23-Oct-2018','DD-MON-YYYY') end_date from dual union all\n",
    "select 'SM4586314' acid,to_date('13-Nov-2017','DD-MON-YYYY') start_date,to_date('23-Oct-2018','DD-MON-YYYY') end_date from dual union all\n",
    "select 'SM4645260' acid,to_date('26-Oct-2017','DD-MON-YYYY') start_date,to_date('09-May-2022','DD-MON-YYYY') end_date from dual union all\n",
    "select 'SM4691399' acid,to_date('19-Nov-2017','DD-MON-YYYY') start_date,to_date('09-Feb-2018','DD-MON-YYYY') end_date from dual union all\n",
    "select 'SM4703819' acid,to_date('27-Feb-2018','DD-MON-YYYY') start_date,to_date('16-Mar-2018','DD-MON-YYYY') end_date from dual union all\n",
    "select 'SM4703782' acid,to_date('27-Feb-2018','DD-MON-YYYY') start_date,to_date('16-Mar-2018','DD-MON-YYYY') end_date from dual union all\n",
    "select 'SM4703848' acid,to_date('27-Feb-2018','DD-MON-YYYY') start_date,to_date('16-Mar-2018','DD-MON-YYYY') end_date from dual union all\n",
    "select 'SM4758745' acid,to_date('09-Feb-2018','DD-MON-YYYY') start_date,to_date('02-Jul-2019','DD-MON-YYYY') end_date from dual union all\n",
    "select 'SM4759102' acid,to_date('09-Feb-2018','DD-MON-YYYY') start_date,to_date('02-Jul-2019','DD-MON-YYYY') end_date from dual union all\n",
    "select 'SM4758776' acid,to_date('09-Feb-2018','DD-MON-YYYY') start_date,to_date('02-Jul-2019','DD-MON-YYYY') end_date from dual union all\n",
    "select 'SM4408557' acid,to_date('09-Jun-2019','DD-MON-YYYY') start_date,to_date('01-Aug-2019','DD-MON-YYYY') end_date from dual union all\n",
    "select 'SM4412414' acid,to_date('31-Jul-2020','DD-MON-YYYY') start_date,to_date('29-Sep-2020','DD-MON-YYYY') end_date from dual\n",
    ") t\n",
    "where gam.acid=t.acid and gam.acid=lam.acid)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd72d81",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
